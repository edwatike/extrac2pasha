# Online Learning для ML-модели

## Обзор

Модуль online learning позволяет ML-модели адаптироваться к новым данным в реальном времени, улучшая качество предсказаний стратегий.

## Как работает обновление

### Процесс обновления

1. **Сбор данных**
   - Каждое применение стратегии записывается в `data/strategy_logs.csv`
   - Запись содержит все признаки и результат применения

2. **Проверка необходимости обновления**
   - Проверяется количество новых записей (по умолчанию ≥ 100)
   - Проверяется время с последнего обновления (по умолчанию ≥ 24 часа)

3. **Обновление модели**
   - Загружаются все доступные данные
   - Модель дообучается через `partial_fit()`
   - Сохраняются новые веса и метаданные

### Признаки для обучения

Модель использует те же признаки, что и для предсказания:

- `protection_type` (тип защиты)
- `user_agent_hash` (хэш user-agent)
- `has_captcha` (наличие капчи)
- `html_title_keywords` (ключевые слова)
- `ip_region` (регион IP)
- `url_depth` (глубина URL)
- `time_of_day` (время суток)

Дополнительно для обучения используются:
- `success` (успешность применения)
- `duration` (время выполнения)

## Настройка параметров

### Параметры обновления

```python
trainer = OnlineTrainer(
    update_threshold=100,        # Количество новых записей для обновления
    update_interval_hours=24     # Интервал обновления в часах
)
```

### Метаданные модели

Файл `models/model_meta.json` содержит:
```json
{
  "last_update": "2024-01-01T12:00:00",
  "last_hash": "md5_hash_of_log_file",
  "total_records": 1000,
  "update_count": 5
}
```

## Использование

### Отслеживание результатов

```python
from src.ml.online_trainer import OnlineTrainer

trainer = OnlineTrainer()

# После применения стратегии
trainer.track_strategy_result(
    strategy_name="playwright_interactive",
    features_dict={
        "protection_type": "cloudflare",
        "user_agent_hash": "chrome_91",
        "ip_region": "RU",
        "html_title_keywords": "access,restricted",
        "time_of_day": "night"
    },
    success=True,
    duration=3.21
)
```

### Принудительное обновление

```python
# Проверить необходимость обновления
if trainer.should_update_model():
    # Обновить модель
    trainer.update_model()
```

## Мониторинг

### Логи

- Все операции логируются через `src.logger`
- Логи сохраняются в `logs/online_learning.log`

### Метрики

- Количество обновлений
- Время последнего обновления
- Размер обучающей выборки
- Хэш файла с логами

## Рекомендации

1. **Частота обновления**
   - Начинайте с частых обновлений (каждые 100 записей)
   - Увеличивайте интервал по мере стабилизации модели

2. **Качество данных**
   - Проверяйте корректность записываемых признаков
   - Удаляйте выбросы и аномалии

3. **Мониторинг производительности**
   - Следите за точностью предсказаний
   - Анализируйте влияние новых данных

## Устранение неполадок

### Проблемы с обновлением

1. **Модель не обновляется**
   - Проверьте права доступа к файлам
   - Убедитесь в корректности данных

2. **Ошибки при обновлении**
   - Проверьте формат данных в логах
   - Убедитесь в совместимости признаков

### Форсирование обновления

1. Удалите `model_meta.json`
2. Установите `update_threshold=1`
3. Добавьте новую запись в лог 